{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries and Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex, re\n",
    "import nltk\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/model-data/comment-2-50.csv\", low_memory=False)\n",
    "df[\"rating\"] = df[\"rating\"].replace(1, 0)\n",
    "df[\"rating\"] = df[\"rating\"].replace(2, 1)\n",
    "df[\"rating\"] = df[\"rating\"].replace(3, 2)\n",
    "df[\"rating\"] = df[\"rating\"].replace(4, 3)\n",
    "df[\"rating\"] = df[\"rating\"].replace(5, 4)\n",
    "df.head(3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[df[\"lang\"] == \"tl\"]\n",
    "data = temp[[\"rating\", \"comment_cleaned_uncased\", \"comment_cleaned_cased\"]]\n",
    "\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        \"comment_cleaned_uncased\": \"msg_uncased\",\n",
    "        \"comment_cleaned_cased\": \"msg_cased\",\n",
    "        \"rating\": \"label\",\n",
    "    }\n",
    ")\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.label.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = regex.sub(r\"\\b([\\p{P}\\p{S}]+?)\\b\", r\"\\1 \", text)\n",
    "    text = \" \".join(text.lower().split()).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_text_cased(text):\n",
    "    text = str(text)\n",
    "    text = regex.sub(r\"\\b([\\p{P}\\p{S}]+?)\\b\", r\"\\1 \", text)\n",
    "    text = \" \".join(text.split()).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# def clean_text(text):\n",
    "#     text = str(text)\n",
    "#     if regex.search(r\"\\b[\\p{P}\\p{S}]\\b\",text):\n",
    "#         print(regex.split(r\"\\b[\\p{P}\\p{S}]\\b\",text))\n",
    "#     return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.msg_uncased = data.msg_uncased.apply(clean_text)\n",
    "data.msg_cased = data.msg_cased.apply(clean_text_cased)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagalog = pd.read_csv(\"../data/tagalog_dict.csv\", low_memory=False, header=None)\n",
    "# tagalog.drop(columns=[1], inplace=True)\n",
    "# tagalog_dict = tagalog[0].tolist()\n",
    "# tagalog_dict[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# Counter([len(word) for word in tagalog_dict])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# dictionary = []\n",
    "# for i in range(5):\n",
    "#     for j in data[data.label == (i + 1)].msg_uncased.tolist():\n",
    "#         dictionary.extend(nltk.word_tokenize(j))\n",
    "\n",
    "# dictionary[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary_without_dups = list(set(dictionary))\n",
    "# Counter([len(word) for word in dictionary_without_dups])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = str(text)\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        if len(token) > 17:\n",
    "            text = text.replace(token, \"\")\n",
    "            text = \" \".join(text.split()).strip()\n",
    "            text = regex.sub(r\" ([\\p{P}\\p{S}]+?) \", r\"\\1 \", text)\n",
    "    text = \" \".join(text.split()).strip()\n",
    "    return text\n",
    "\n",
    "data.msg_uncased = data.msg_uncased.apply(normalize_text)\n",
    "data.msg_cased = data.msg_cased.apply(normalize_text)\n",
    "data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neilc\\AppData\\Local\\Temp\\ipykernel_22380\\2799562573.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_data = model_data.append(data[data.label == i].sample(1000))\n",
      "C:\\Users\\Neilc\\AppData\\Local\\Temp\\ipykernel_22380\\2799562573.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_data = model_data.append(data[data.label == i].sample(1000))\n",
      "C:\\Users\\Neilc\\AppData\\Local\\Temp\\ipykernel_22380\\2799562573.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_data = model_data.append(data[data.label == i].sample(1000))\n",
      "C:\\Users\\Neilc\\AppData\\Local\\Temp\\ipykernel_22380\\2799562573.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_data = model_data.append(data[data.label == i].sample(1000))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m model_data\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;32m      5\u001b[0m model_data\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;32m----> 7\u001b[0m model\u001b[39m.\u001b[39mshape\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_data = data[data.label == 0].sample(1000)\n",
    "for i in range(1, 5):\n",
    "    model_data = model_data.append(data[data.label == i].sample(1000))\n",
    "model_data.reset_index(drop=True, inplace=True)\n",
    "model_data.shape\n",
    "\n",
    "model_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.to_csv(\"../data/model-data/dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
